{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsflfm.analysis import (\n",
    "    ResultManager,\n",
    "    ResultPlotter,\n",
    "    BulkAnalyzer,\n",
    "    convert_to_percentile,\n",
    "    get_random_percentile_index,\n",
    "    sort_by_camera,\n",
    "    get_percentiles,\n",
    ")\n",
    "from hsflfm.util import MetadataManager\n",
    "from scipy.spatial import cKDTree\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from hsflfm.util import (\n",
    "    load_dictionary,\n",
    "    save_dictionary,\n",
    "    play_video,\n",
    "    create_video_from_numpy_array,\n",
    ")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the filenames\n",
    "all_filenames = []\n",
    "f = \"test_full_results_from_manual_strike_transfer\"\n",
    "# f = \"temporary_result_storage_5\"\n",
    "folders = os.listdir(f)\n",
    "for inner in folders:\n",
    "    path = Path(f) / inner\n",
    "    if path.is_dir():\n",
    "        filenames = os.listdir(path)\n",
    "        for filename in filenames:\n",
    "            if filename[-4:] == \"json\":\n",
    "                all_filenames.append(str(path / filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit this if the naming convention changes\n",
    "def get_filename(specimen_number, strike_number):\n",
    "    return f\"{f}/{specimen_number}/strike_{strike_number}_results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_filenames))\n",
    "# print(all_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = BulkAnalyzer(all_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload = True\n",
    "res_filename = \"test_full_results_from_manual_strike_transfer/loaded_results.json\"\n",
    "# res_filename = \"temp_loaded_results_5.json\"\n",
    "\n",
    "\n",
    "if reload:\n",
    "\n",
    "    analyzer.load_results()\n",
    "    save_dictionary(analyzer.all_results, res_filename)\n",
    "else:\n",
    "    analyzer.all_results = load_dictionary(res_filename)\n",
    "\n",
    "    for key, value in analyzer.all_results.items():\n",
    "\n",
    "        if key in [\"specimen_number\", \"mandible_order\"]:\n",
    "\n",
    "            analyzer.all_results[key] = np.asarray(value)\n",
    "\n",
    "            continue\n",
    "\n",
    "        analyzer.all_results[key] = torch.asarray(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a \"good point\" for now\n",
    "error_scores = analyzer.error_scores\n",
    "good_indices = torch.where(error_scores < 0.0015)[0]\n",
    "\n",
    "print(\"good ratio: {:.2f}\".format(len(good_indices) / len(error_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all results on the mesh\n",
    "\n",
    "p = analyzer.all_results[\"mesh_points\"]\n",
    "\n",
    "# jitter the points\n",
    "\n",
    "jitter = 10000\n",
    "\n",
    "rand = (torch.rand(p.shape) - 0.5) * jitter\n",
    "\n",
    "p = p + rand\n",
    "\n",
    "v = analyzer.all_results[\"normalized_displacement\"][:, 2]\n",
    "v = analyzer.all_results[\"displacement\"][:, 2]\n",
    "\n",
    "v = v[good_indices]\n",
    "\n",
    "v = convert_to_percentile(v)\n",
    "\n",
    "\n",
    "fig = ResultPlotter.plot_mesh_with_points(\n",
    "    points=p[good_indices],\n",
    "    opacity=0.2,\n",
    "    point_values=v,\n",
    "    points_on_surface=False,\n",
    "    marker_dict={\"size\": 0.7, \"colorscale\": \"Turbo\", \"opacity\": 0.7},\n",
    ")\n",
    "\n",
    "from hsflfm.ant_model import M_mesh_ant, mesh_scale\n",
    "from hsflfm.util import matmul\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "std_radius = 200\n",
    "theta = np.linspace(0, 2 * np.pi, 200)\n",
    "x = np.cos(theta) * std_radius\n",
    "y = np.sin(theta) * std_radius * -1\n",
    "z = np.zeros_like(theta)\n",
    "points = np.concatenate((x[:, None], y[:, None], z[:, None]), axis=1)\n",
    "mesh_points = matmul(np.linalg.inv(M_mesh_ant), points) * mesh_scale * 0.1\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter3d(\n",
    "#         x=mesh_points[:, 0],\n",
    "#         y=mesh_points[:, 1],\n",
    "#         z=mesh_points[:, 2],\n",
    "#         mode='lines',\n",
    "#         marker={\n",
    "#             \"size\": 100, \"color\": 'black'\n",
    "#         }\n",
    "\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out getting a strength score for each video\n",
    "specimen_names = MetadataManager.all_specimen_numbers()\n",
    "specimen_names_old = specimen_names.copy()\n",
    "scores = []\n",
    "names = []\n",
    "strike_nums = []\n",
    "\n",
    "switch_names = [\"20240418_OB_1\", \"20240422_OB_1\", \"20240427_OB_5\"]\n",
    "for n in switch_names:\n",
    "    specimen_names_old[np.where(specimen_names == n)] = \"2022\" + n[4:]\n",
    "\n",
    "all_error_scores = analyzer.error_scores\n",
    "named_scores = {}\n",
    "for name in tqdm(specimen_names_old):\n",
    "    strike_numbers = MetadataManager(name).strike_numbers\n",
    "    named_scores[name] = {}\n",
    "    for strike_number in strike_numbers:\n",
    "        strike_number = int(strike_number)\n",
    "        idx = analyzer.get_specimen_indices(name, strike_number=strike_number)\n",
    "        # only use points below the threshold\n",
    "        idx = np.intersect1d(idx, good_indices)\n",
    "\n",
    "        if len(idx) < 1:\n",
    "            print(name)\n",
    "\n",
    "        # if len(idx) < 15:\n",
    "        #     print(f\"skipping {name} strike {strike_number}, {len(idx)} points\")\n",
    "        #     continue\n",
    "\n",
    "        k = 15\n",
    "        _, neighbor_indices = analyzer.get_closest_point_indices(\n",
    "            k=k, indices=good_indices\n",
    "        )\n",
    "        neighbor_indices = neighbor_indices[idx]\n",
    "\n",
    "        ratios = np.zeros(neighbor_indices.shape[0])\n",
    "        for pi, neighbor_index in enumerate(neighbor_indices):\n",
    "            displacements = analyzer.all_results[\"displacement\"][neighbor_index]\n",
    "            disp_norm = displacements[:, :2]\n",
    "\n",
    "            point_disp = analyzer.all_results[\"displacement\"][idx[pi]][2]\n",
    "            ratios[pi] = torch.abs(point_disp) / torch.mean(torch.abs(disp_norm))\n",
    "\n",
    "        score = np.mean(ratios)\n",
    "        scores.append(score)\n",
    "        strike_nums.append(strike_number)\n",
    "        names.append(name)\n",
    "\n",
    "        named_scores[name][strike_number] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "delays = []\n",
    "\n",
    "for name, old_name in zip(specimen_names, specimen_names_old):\n",
    "    if \"20220418_OB_1\" in old_name:\n",
    "        continue\n",
    "    mm = MetadataManager(name)\n",
    "    strike_numbers = mm.strike_numbers\n",
    "    for num in strike_numbers:\n",
    "        try:\n",
    "            num = int(num)\n",
    "            mandible_frames = mm.mandible_start_frames(strike_number=num)\n",
    "            diff = mandible_frames[0] - mandible_frames[1]\n",
    "            frame_rate = int(mm.get_strike_data(num)[\"Frame Rate\"])\n",
    "            diff = diff / frame_rate * 1e3\n",
    "\n",
    "            scores.append(named_scores[old_name][num])\n",
    "            delays.append(diff)\n",
    "        except Exception as e:\n",
    "            print(f\"skipping {name}, strike {num}, {e}\")\n",
    "plt.scatter(delays, scores)\n",
    "plt.xlabel(\"Mandible delay (ms)\")\n",
    "plt.ylabel(\"Strength Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.where(analyzer.all_results[\"mandible_order\"] == \"R only\")[0]\n",
    "# np.random.shuffle(indices)\n",
    "# index = indices[0]\n",
    "# specimen_name = analyzer.all_results[\"specimen_number\"][index]\n",
    "# strike_number = analyzer.all_results[\"specimen_number\"][index]\n",
    "# filename = f\"temporary_result_storage_5/{name}/strike_{num}_results.json\"\n",
    "# plotter = ResultPlotter(load_dictionary(filename))\n",
    "# video = plotter.get_arrow_video(movement_mag=5, disp_threshold=5e-3,\n",
    "#                                 force_arrow_after_strike=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign the strength scores to each point\n",
    "strength_scores = torch.zeros_like(analyzer.error_scores)\n",
    "for name, strike_num, score in zip(names, strike_nums, scores):\n",
    "    idx0 = np.where(analyzer.all_results[\"specimen_number\"] == name)[0]\n",
    "    idx1 = np.where(analyzer.all_results[\"strike_number\"] == strike_num)[0]\n",
    "\n",
    "    indices = np.intersect1d(idx0, idx1)\n",
    "    strength_scores[indices] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(scores, bins=50)\n",
    "plt.title(\"Strength Scores\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm curious which specimens have the largest variation in strike strength\n",
    "# so somewhat inefficiently re-find the strength score for each strike\n",
    "# and see how it varies\n",
    "stds = []\n",
    "for name in tqdm(specimen_names):\n",
    "    strike_numbers = MetadataManager(name).strike_numbers\n",
    "    scores = []\n",
    "    for strike_number in strike_numbers:\n",
    "        idx = analyzer.get_specimen_indices(name, strike_number=strike_number)\n",
    "        if len(idx) < 1:\n",
    "            continue\n",
    "        strength_score = strength_scores[idx[0]]\n",
    "        scores.append(strength_score)\n",
    "\n",
    "    stds.append(np.std(scores))\n",
    "    print(name, \"{:.2f}\".format(np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can probably be deleted\n",
    "name = \"20240503_OB_4\"\n",
    "highlight_point = 23\n",
    "strike_numbers = MetadataManager(name).strike_numbers\n",
    "\n",
    "# cheating a bit here\n",
    "# min_disp = np.inf\n",
    "# max_disp = -np.inf\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "cmap = matplotlib.cm.coolwarm\n",
    "plt.figure()\n",
    "\n",
    "disp = []\n",
    "vel = []\n",
    "c = []\n",
    "for num in strike_numbers:\n",
    "    filename = f\"temporary_result_storage_5/{name}/strike_{num}_results.json\"\n",
    "    filename = f\"test_full_results_from_manual_strike_transfer/{name}/strike_{num}_results.json\"\n",
    "    res = load_dictionary(filename)\n",
    "    point_index = np.where(np.asarray(res[\"point_numbers\"]) == highlight_point)[0][0]\n",
    "    rm = ResultManager(res)\n",
    "\n",
    "    # peak_index = rm.get_peak_indices()[point_index]\n",
    "    peak_disp = rm.peak_displacements()[point_index]\n",
    "\n",
    "    strike_center = int(rm.strike_center_index())\n",
    "    rel_displacements = rm.rel_displacements[\n",
    "        :, strike_center - 5 : strike_center + 11, 2\n",
    "    ]\n",
    "    frame_rate = 100e3  # shouldn't be hardcoding this...\n",
    "    x_axis = np.arange(rel_displacements.shape[1]) / frame_rate * 1e3\n",
    "    plt.figure()\n",
    "    for p in rel_displacements:\n",
    "        plt.plot(x_axis, p * 1e3, color=\"black\")\n",
    "    plt.plot(\n",
    "        x_axis,\n",
    "        1e3 * rel_displacements[point_index],\n",
    "        color=\"red\",\n",
    "        label=f\"point {highlight_point}\",\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time (ms)\")\n",
    "    plt.ylabel(\"Displacement (um)\")\n",
    "    plt.title(f\"{name}, strike{num}\")\n",
    "\n",
    "    plotter = ResultPlotter(res)\n",
    "    # plotter.plot_all_displacement(good_only=True, highlight_point=highlight_point)\n",
    "    plotter.scatter_peak_disp(good_only=True, highlight_point=highlight_point)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\n",
    "        f\"{name} strike {num}, \\n point {highlight_point} circled \\n displacement (mm)\"\n",
    "    )\n",
    "\n",
    "\n",
    "plotter.show_image_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can probably be deleted\n",
    "name = \"20240503_OB_4\"\n",
    "highlight_point = 23\n",
    "strike_numbers = MetadataManager(name).strike_numbers\n",
    "\n",
    "# cheating a bit here\n",
    "# min_disp = np.inf\n",
    "# max_disp = -np.inf\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "cmap = matplotlib.cm.coolwarm\n",
    "plt.figure()\n",
    "\n",
    "disp = []\n",
    "vel = []\n",
    "c = []\n",
    "\n",
    "mm = MetadataManager(name)\n",
    "\n",
    "for num in strike_numbers:\n",
    "    filename = f\"temporary_result_storage_5/{name}/strike_{num}_results.json\"\n",
    "    filename = f\"test_full_results_from_manual_strike_transfer/{name}/strike_{num}_results.json\"\n",
    "    res = load_dictionary(filename)\n",
    "    point_index = np.where(np.asarray(res[\"point_numbers\"]) == highlight_point)[0][0]\n",
    "    rm = ResultManager(res)\n",
    "\n",
    "    # peak_index = rm.get_peak_indices()[point_index]\n",
    "    peak_disp = rm.peak_displacements()[point_index]\n",
    "\n",
    "    min_disp = min(peak_disp, min_disp)\n",
    "    max_disp = max(peak_disp, max_disp)\n",
    "\n",
    "    c_value = (peak_disp - min_disp) / (max_disp - min_disp)\n",
    "    color = cmap(c_value)\n",
    "\n",
    "    strike_center = int(rm.strike_center_index())\n",
    "    velocities, vel_indices = rm.max_abs_velocity(return_indices=True)\n",
    "    strike_center = vel_indices[point_index]\n",
    "\n",
    "    frame_rate = 100e3  # shouldn't be hardcoding this...\n",
    "    x_axis = np.arange(-9, 9) / frame_rate * 1e3\n",
    "    plt.plot(\n",
    "        x_axis,\n",
    "        1e3\n",
    "        * rm.rel_displacements[point_index, strike_center - 9 : strike_center + 9, 2]\n",
    "        / peak_disp,\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "    mandible_frame = mm.mandible_start_frames(strike_number=num)[0] - strike_center\n",
    "    plt.axvline(mandible_frame / frame_rate * 1e3, color=color)\n",
    "\n",
    "    disp.append(peak_disp)\n",
    "    vel.append(velocities[point_index])\n",
    "    c.append(color)\n",
    "    # plotter = ResultPlotter(res)\n",
    "    # plotter.plot_all_displacement(good_only=True, highlight_point=23)\n",
    "    # plotter.scatter_peak_disp(good_only=True, highlight_point=23)\n",
    "# plotter.show_image_numbers()\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Displacement (um)\")\n",
    "plt.title(f\"Point {highlight_point} trajectories for {name}\")\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor(\"black\")\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(disp, vel, c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = np.nanargmax(scores)\n",
    "# name = names[n]\n",
    "# num = strike_nums[n]\n",
    "\n",
    "# strike_indices = analyzer.get_specimen_indices(name, num)\n",
    "# good_strike_indices = np.intersect1d(strike_indices, good_indices)\n",
    "# print(name, \"strike\", num, \"score:\", scores[n])\n",
    "\n",
    "# filename = f\"temporary_result_storage_4/{name}/strike_{num}_results.json\"\n",
    "# assert os.path.exists(filename)\n",
    "\n",
    "# result_info = load_dictionary(filename)\n",
    "# plotter = ResultPlotter(result_info)\n",
    "\n",
    "# plotter.scatter_peak_disp(highlight_point=10)\n",
    "\n",
    "\n",
    "# fig = plotter.plot_all_displacement(highlight_point=10)\n",
    "# # highlight the points below the error threshold in blue\n",
    "# ax = fig.axes[0]\n",
    "# bad_disp = plotter.result_manager.rel_displacements[~strike_good_point_indices]\n",
    "# for p in bad_disp:\n",
    "#     plt.plot(p[:, 2] * 1e3, \"--\", color=(0.5, 0.5, 1))\n",
    "# # plotter.plot_displacement(10)\n",
    "\n",
    "# #vid = plotter.get_arrow_video(cam_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.nanargmax(scores)\n",
    "name = names[n]\n",
    "num = strike_nums[n]\n",
    "\n",
    "strike_indices = analyzer.get_specimen_indices(name, num)\n",
    "print(name, \"strike\", num, \"score:\", scores[n])\n",
    "\n",
    "filename = f\"temporary_result_storage_4/{name}/strike_{num}_results.json\"\n",
    "assert os.path.exists(filename)\n",
    "\n",
    "result_info = load_dictionary(filename)\n",
    "plotter = ResultPlotter(result_info)\n",
    "good_strike_indices, plotter.good_indices, _ = np.intersect1d(\n",
    "    strike_indices, good_indices, return_indices=True\n",
    ")\n",
    "plotter.scatter_peak_disp(highlight_point=10)\n",
    "plotter.scatter_peak_disp(good_only=False)\n",
    "\n",
    "\n",
    "fig = plotter.plot_all_displacement(highlight_point=10)\n",
    "\n",
    "vid = plotter.get_arrow_video(cam_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to plot a bunch of points from different strikes\n",
    "# find points in the region I want\n",
    "distances = torch.linalg.norm(\n",
    "    analyzer.all_results[\"start_locations_std\"][:, :2], axis=1\n",
    ")\n",
    "low_indices = torch.where(distances < 200)[0]\n",
    "\n",
    "# and for simplicity, only those with positive velocity\n",
    "pos_vel_indices = torch.where(analyzer.all_results[\"max_z_velocity\"][:, 2] > 0)\n",
    "\n",
    "indices = np.intersect1d(good_indices, low_indices)\n",
    "indices = np.intersect1d(indices, pos_vel_indices)\n",
    "\n",
    "min_disp = np.inf\n",
    "max_disp = -np.inf\n",
    "\n",
    "\n",
    "# silly way to handle this, but its fine....\n",
    "data = np.zeros((len(indices), 18))\n",
    "strike_centers = np.zeros(len(indices))\n",
    "\n",
    "plt.figure()\n",
    "for i, index in enumerate(tqdm(indices)):\n",
    "    try:\n",
    "        point_number = analyzer.all_results[\"point_number\"][index]\n",
    "        name = analyzer.all_results[\"specimen_number\"][index]\n",
    "        strike_number = int(analyzer.all_results[\"strike_number\"][index])\n",
    "\n",
    "        # filename = (\n",
    "        #     f\"temporary_result_storage_5/{name}/strike_{strike_number}_results.json\"\n",
    "        # )\n",
    "        filename = f\"test_full_results_from_manual_strike_transfer/{name}/strike_{num}_results.json\"\n",
    "        res = load_dictionary(filename)\n",
    "        rm = ResultManager(res)\n",
    "\n",
    "        point_index = np.where(np.asarray(res[\"point_numbers\"]) == point_number)[0][0]\n",
    "\n",
    "        peak_disp = rm.peak_displacements()[point_index]\n",
    "\n",
    "        min_disp = min(peak_disp, min_disp)\n",
    "        max_disp = max(peak_disp, max_disp)\n",
    "\n",
    "        velocities, vel_indices = rm.max_abs_velocity(return_indices=True)\n",
    "        strike_center = vel_indices[point_index]\n",
    "\n",
    "        frame_rate = int(\n",
    "            MetadataManager(name).get_strike_data(strike_number)[\"Frame Rate\"]\n",
    "        )\n",
    "        if frame_rate < 0.9e5:\n",
    "            print(f\"small frame rate for {name} {strike_number}\")\n",
    "            continue\n",
    "        x_axis = np.arange(-9, 9) / frame_rate * 1e3\n",
    "        plt.plot(\n",
    "            x_axis,\n",
    "            1e3\n",
    "            * rm.rel_displacements[\n",
    "                point_index, strike_center - 9 : strike_center + 9, 2\n",
    "            ]\n",
    "            / peak_disp,\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "        data[i] = rm.rel_displacements[\n",
    "            point_index, strike_center - 9 : strike_center + 9, 2\n",
    "        ]\n",
    "        strike_centers[i] = strike_center\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"failed on {name}, strike {strike_number}, point {point_number}, {e}\")\n",
    "\n",
    "    # if i > 50:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "maxv = np.max(data)\n",
    "minv = 0.008\n",
    "print(minv, maxv)\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "cmap = matplotlib.cm.magma\n",
    "\n",
    "for i, p in enumerate(data):\n",
    "    p = p - p[0]\n",
    "    if np.max(np.abs(p)) < minv:\n",
    "        continue\n",
    "\n",
    "    # p = np.diff(p)\n",
    "\n",
    "    index = indices[i]\n",
    "    specimen_name = analyzer.all_results[\"specimen_number\"][index]\n",
    "    strike_number = int(analyzer.all_results[\"strike_number\"][index])\n",
    "    mm = MetadataManager(specimen_name)\n",
    "    frame = mm.mandible_start_frames(strike_number)[0]\n",
    "    # print(frame, strike_centers[i])\n",
    "    frame = frame - strike_centers[i]\n",
    "    frame = frame + (np.random.random() * 0.5) - 0.25\n",
    "\n",
    "    # print(frame)\n",
    "\n",
    "    peak = np.max(np.abs(p))\n",
    "    color = cmap((peak - minv) / (maxv - minv))\n",
    "\n",
    "    # p2 = np.diff(p)\n",
    "    # x_axis = (np.arange(len(p2)) - 9) / 1e5 * 1e3\n",
    "\n",
    "    # p2 is in mm/frame\n",
    "    # p2 = p2 * 100000 / 1000 #(m/s)\n",
    "\n",
    "    # p = np.diff(p)\n",
    "    plt.plot(\n",
    "        p, linewidth=0.4, color=color  # / np.max(np.abs(p[1:])),\n",
    "    )  # / np.max(np.abs(p)),\n",
    "\n",
    "    mandible_order = mm.mandible_order(strike_number)\n",
    "    if mandible_order == \"L\":\n",
    "        c2 = \"red\"\n",
    "    elif mandible_order == \"R\":\n",
    "        c2 = \"green\"\n",
    "    elif mandible_order == \"S\":\n",
    "        c2 = \"blue\"\n",
    "    elif mandible_order == \"L only\":\n",
    "        c2 = \"purple\"\n",
    "    else:\n",
    "        c2 = \"white\"\n",
    "\n",
    "    # plt.axvline(frame / 1e5 * 1e3, color=c2)\n",
    "    count += 1\n",
    "print(count)\n",
    "\n",
    "ax = plt.gca()\n",
    "# ax.set_ylim(-1, 1)\n",
    "ax.set_facecolor(\"black\")\n",
    "plt.ylabel(\"Velocity\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.title(\n",
    "    f\"Velocity normalized by max displacement for {count} points in saddle region\"\n",
    ")\n",
    "ax = plt.gca()\n",
    "# ax.set_yticks([])\n",
    "\n",
    "# r = np.random.random((500, 500)) * (maxv - minv) + minv\n",
    "# plt.figure()\n",
    "# plt.imshow(r * 1e3, cmap=cmap)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.linalg.norm(analyzer.all_results[\"max_z_velocity\"][good_indices], axis=1)\n",
    "d = np.linalg.norm(analyzer.all_results[\"displacement\"][good_indices], axis=1)\n",
    "plt.scatter(d, v, s=2)\n",
    "\n",
    "distances = torch.linalg.norm(\n",
    "    analyzer.all_results[\"start_locations_std\"][good_indices, :2], axis=1\n",
    ")\n",
    "low_indices = torch.where(distances < 200)[0]\n",
    "\n",
    "plt.figure()\n",
    "frame_rate = 1e5\n",
    "plt.scatter(d[low_indices] * 1e3, v[low_indices] * frame_rate, s=2)\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel(r\"max |displacement| (um)\")\n",
    "ax.set_ylabel(r\"max |velocity| (mm/sec)\")\n",
    "ax.set_title(f\"Displacement vs Velocity for {len(low_indices)} Points in Saddle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = analyzer.all_results[\"start_locations_std\"][good_indices]\n",
    "plt.scatter(locs[:, 1], locs[:, 0], c=d, s=2)\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = analyzer.all_results[\"max_z_velocity\"][good_indices, 2]\n",
    "d = analyzer.all_results[\"displacement\"][good_indices, 2]\n",
    "plt.scatter(d, v, s=2)\n",
    "plt.ylabel(\"max velocities (mm/frame)\")\n",
    "plt.xlabel(\"max displacement(mm)\")\n",
    "\n",
    "# then restrict to points in the saddle kind of\n",
    "# for simplicity, going within 100 standardized units of (0, 0)\n",
    "# plt.figure()\n",
    "# x = analyzer.all_results[\"start_locations_std\"][:, 0]\n",
    "# y = analyzer.all_results[\"start_locations_std\"][:, 1]\n",
    "# c = analyzer.all_results[\"normalized_displacement\"][:, 2]\n",
    "# plt.scatter(y[good_indices], x[good_indices], c=c[good_indices], s=2, cmap='turbo',\n",
    "#             clim=(-2, 4))\n",
    "# ax = plt.gca()\n",
    "# ax.set_aspect(\"equal\")\n",
    "# ax.invert_xaxis()\n",
    "# plt.colorbar()\n",
    "\n",
    "distances = torch.linalg.norm(\n",
    "    analyzer.all_results[\"start_locations_std\"][:, :2], axis=1\n",
    ")\n",
    "low_indices = torch.where(distances < 200)[0]\n",
    "indices = np.intersect1d(good_indices.numpy(), low_indices.numpy())\n",
    "\n",
    "v = analyzer.all_results[\"max_z_velocity\"][indices, 2]\n",
    "d = analyzer.all_results[\"displacement\"][indices, 2]\n",
    "orders = analyzer.all_results[\"mandible_order\"][indices]\n",
    "r_only_indices = np.where(orders == \"R only\")[0]\n",
    "\n",
    "\n",
    "idx = np.where(v > 0)[0]\n",
    "slope, offset = np.polyfit(v[idx], d[idx], deg=1)\n",
    "x_vals = np.linspace(0, 0.01, 100)\n",
    "y_vals = x_vals * slope + offset\n",
    "plt.figure()\n",
    "R = np.corrcoef(v[idx], d[idx])[0, 1]\n",
    "R_Squared = R * R\n",
    "# plt.plot(x_vals, y_vals, label=\"r^2 = {:.2f}\".format(R_Squared))\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "plt.scatter(d, v, s=2)\n",
    "plt.scatter(d[r_only_indices], v[r_only_indices], s=2, color=\"red\")\n",
    "plt.ylabel(\"max velocities (mm/frame)\")\n",
    "plt.xlabel(\"max displacement(mm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = analyzer.all_results[\"start_locations_std\"][good_indices]\n",
    "v = analyzer.all_results[\"max_z_velocity\"][good_indices, 2]\n",
    "d = analyzer.all_results[\"displacement\"][good_indices, 2]\n",
    "plt.scatter(locs[:, 1], locs[:, 0], c=v, s=2, cmap=\"turbo\")\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusing_indices = indices[np.where(v < 0)[0]]\n",
    "for i in confusing_indices:\n",
    "    # print(analyzer.all_results[\"mandible_order\"][i])\n",
    "    # break\n",
    "    if \"R only\" not in analyzer.all_results[\"mandible_order\"][i]:\n",
    "        print(\n",
    "            analyzer.all_results[\"specimen_number\"][i],\n",
    "            int(analyzer.all_results[\"strike_number\"][i]),\n",
    "            int(analyzer.all_results[\"point_number\"][i]),\n",
    "            analyzer.all_results[\"mandible_order\"][i],\n",
    "        )\n",
    "        # print(analyzer.all_results[\"displacement\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"temporary_result_storage_5/20220427_OB_4/strike_1_results.json\"\n",
    "info = load_dictionary(filename)\n",
    "plotter = ResultPlotter(info)\n",
    "plotter.scatter_peak_disp(highlight_point=14)\n",
    "plotter.plot_all_displacement(highlight_point=14)\n",
    "plotter.scatter_peak_disp(with_image=True)\n",
    "\n",
    "video = plotter.get_arrow_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(video, fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a band\n",
    "idx0 = torch.where(d > 0.019)[0]\n",
    "idx1 = torch.where(d < 0.021)[0]\n",
    "idx = np.intersect1d(idx0.numpy(), idx1.numpy())\n",
    "idx = indices[idx]\n",
    "\n",
    "for i in idx:\n",
    "    specimen_number = analyzer.all_results[\"specimen_number\"][i]\n",
    "    point_number = int(analyzer.all_results[\"point_number\"][i])\n",
    "    strike_number = int(analyzer.all_results[\"strike_number\"][i])\n",
    "    # print(specimen_number, \"point\", point_number, \"strike\", strike_number, \"index\", i)\n",
    "\n",
    "\n",
    "spec_indices = analyzer.get_specimen_indices(\"20220427_OB_5\")\n",
    "point_indices = torch.where(analyzer.all_results[\"point_number\"] == 49)[0]\n",
    "spec_indices1 = np.intersect1d(spec_indices, point_indices)\n",
    "spec_indices1 = np.intersect1d(spec_indices1, good_indices)\n",
    "strike_nums = analyzer.all_results[\"strike_number\"][spec_indices1]\n",
    "args = np.argsort(strike_nums)\n",
    "spec_indices1 = spec_indices1[args]\n",
    "\n",
    "point_indices2 = torch.where(analyzer.all_results[\"point_number\"] == 5)[0]\n",
    "spec_indices2 = np.intersect1d(spec_indices, point_indices2)\n",
    "spec_indices2 = np.intersect1d(spec_indices2, good_indices)\n",
    "strike_nums = analyzer.all_results[\"strike_number\"][spec_indices2]\n",
    "args = np.argsort(strike_nums)\n",
    "spec_indices2 = spec_indices2[args]\n",
    "\n",
    "v = analyzer.all_results[\"max_z_velocity\"][spec_indices1, 2]\n",
    "d = analyzer.all_results[\"displacement\"][spec_indices1, 2]\n",
    "\n",
    "v2 = analyzer.all_results[\"max_z_velocity\"][spec_indices2, 2]\n",
    "d2 = analyzer.all_results[\"displacement\"][spec_indices2, 2]\n",
    "plt.scatter(v, d)\n",
    "plt.scatter(v2, d2)\n",
    "\n",
    "\n",
    "diff = d - d2\n",
    "plt.scatter(v, diff)\n",
    "\n",
    "# cheating with this...\n",
    "mandible_diffs = [14, 2, 3, 0, 0, 4, 0, 2, 2, 1, 2, 2, 1, 2, 0, 2, 3, 1, 0, 2, 1]\n",
    "\n",
    "mand_start = np.asarray(\n",
    "    [29, 14, 15, 16, 19, 19, 4, 13, 8, 22, 12, 12, 18, 5, 16, 29, 35, 7, 17, 5, 9]\n",
    ")\n",
    "\n",
    "strike_end = np.asarray(\n",
    "    [55, 22, 24, 24, 28, 28, 11, 20, 17, 29, 19, 18, 25, 13, 22, 37, 42, 15, 24, 13, 18]\n",
    ")\n",
    "frame_diff = strike_end - mand_start\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(diff, mandible_diffs)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(diff, frame_diff - mandible_diffs)\n",
    "\n",
    "mm = MetadataManager(\"20220427_OB_5\")\n",
    "# plt.figure()\n",
    "# for strike_num in mm.strike_numbers:\n",
    "filename = f\"{f}/20220427_OB_5/strike_{strike_num}_results.json\"\n",
    "res = load_dictionary(filename)\n",
    "#     point_index = np.where(np.asarray(res[\"point_numbers\"])==49)[0][0]\n",
    "#     plt.plot(np.asarray(res[\"rel_displacements\"])[point_index, :, 2])\n",
    "plotter = ResultPlotter(res)\n",
    "# plotter.scatter_peak_disp(highlight_point=49)\n",
    "plotter.show_image_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mm.get_start_images(strike_number=1)[2]\n",
    "match_points = np.asarray(load_dictionary(mm.match_points_filename)[2])\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "points = [5, 49]\n",
    "plt.scatter([match_points[points, 1]], [match_points[points, 0]])\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(40, 120)\n",
    "ax.set_ylim(150, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"20240430_OB_2\"\n",
    "num = 1\n",
    "filename = f\"temporary_result_storage_4/{name}/strike_{num}_results.json\"\n",
    "\n",
    "spec_indices = analyzer.get_specimen_indices(name)\n",
    "point_indices = torch.where(analyzer.all_results[\"point_number\"] == 28)[0]\n",
    "spec_indices1 = np.intersect1d(spec_indices, point_indices)\n",
    "spec_indices1 = np.intersect1d(spec_indices1, good_indices)\n",
    "strike_nums = analyzer.all_results[\"strike_number\"][spec_indices1]\n",
    "args = np.argsort(strike_nums)\n",
    "spec_indices1 = spec_indices1[args]\n",
    "\n",
    "point_indices2 = torch.where(analyzer.all_results[\"point_number\"] == 8)[0]\n",
    "spec_indices2 = np.intersect1d(spec_indices, point_indices2)\n",
    "print(len(spec_indices2))\n",
    "spec_indices2 = np.intersect1d(spec_indices2, good_indices)\n",
    "print(len(spec_indices2))\n",
    "strike_nums = analyzer.all_results[\"strike_number\"][spec_indices2]\n",
    "args = np.argsort(strike_nums)\n",
    "spec_indices2 = spec_indices2[args]\n",
    "\n",
    "v = analyzer.all_results[\"max_z_velocity\"][spec_indices1, 2]\n",
    "d = analyzer.all_results[\"displacement\"][spec_indices1, 2]\n",
    "\n",
    "v2 = analyzer.all_results[\"max_z_velocity\"][spec_indices2, 2]\n",
    "d2 = analyzer.all_results[\"displacement\"][spec_indices2, 2]\n",
    "plt.scatter(v, d)\n",
    "plt.scatter(v2, d2)\n",
    "\n",
    "\n",
    "# diff = d - d2\n",
    "# plt.scatter(v, diff)\n",
    "\n",
    "# # cheating with this...\n",
    "# mandible_diffs = [14, 2, 3, 0, 0,\n",
    "#                   4, 0, 2, 2, 1,\n",
    "#                   2, 2, 1, 2, 0,\n",
    "#                   2, 3, 1, 0, 2, 1]\n",
    "\n",
    "# mand_start = np.asarray([\n",
    "#     29, 14, 15, 16, 19,\n",
    "#     19, 4, 13, 8, 22,\n",
    "#     12, 12, 18, 5, 16,\n",
    "#     29, 35, 7, 17, 5, 9\n",
    "# ])\n",
    "\n",
    "# strike_end = np.asarray([\n",
    "#     55, 22, 24, 24, 28,\n",
    "#     28, 11, 20, 17, 29,\n",
    "#     19, 18, 25, 13, 22,\n",
    "#     37, 42, 15, 24, 13, 18\n",
    "# ])\n",
    "# frame_diff = strike_end - mand_start\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(diff, mandible_diffs)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(frame_diff, mandible_diffs)\n",
    "\n",
    "# mm = MetadataManager(\"20220427_OB_5\")\n",
    "# plt.figure()\n",
    "# for strike_num in mm.strike_numbers:\n",
    "#     filename = f\"{f}/20220427_OB_5/strike_{strike_num}_results.json\"\n",
    "res = load_dictionary(filename)\n",
    "#     point_index = np.where(np.asarray(res[\"point_numbers\"])==49)[0][0]\n",
    "#     plt.plot(np.asarray(res[\"rel_displacements\"])[point_index, :, 2])\n",
    "plotter = ResultPlotter(res)\n",
    "plotter.scatter_peak_disp()\n",
    "plotter.show_image_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all results on the mesh\n",
    "p = analyzer.all_results[\"mesh_points\"]\n",
    "\n",
    "# jitter the points\n",
    "jitter = 10000\n",
    "rand = (torch.rand(p.shape) - 0.5) * jitter\n",
    "p = p + rand\n",
    "\n",
    "v = analyzer.all_results[\"normalized_displacement\"][:, 2]\n",
    "# v = analyzer.all_results[\"displacement\"][:, 2]\n",
    "good_point_indices = torch.where(analyzer.error_scores < 0.0015)[0]\n",
    "strength_threshold = 1.4\n",
    "\n",
    "weak_indices = np.intersect1d(\n",
    "    good_point_indices, np.where(strength_scores < strength_threshold)[0]\n",
    ")\n",
    "v = v[weak_indices]\n",
    "v = convert_to_percentile(v)\n",
    "\n",
    "ResultPlotter.plot_mesh_with_points(\n",
    "    points=p[weak_indices],\n",
    "    opacity=0.2,\n",
    "    point_values=v,\n",
    "    points_on_surface=False,\n",
    "    marker_dict={\"size\": 1, \"colorscale\": \"Turbo\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength_threshold = 1\n",
    "\n",
    "strong_indices = np.intersect1d(\n",
    "    good_point_indices, np.where(strength_scores > strength_threshold)[0]\n",
    ")\n",
    "v = analyzer.all_results[\"displacement\"][:, 2]\n",
    "v = v[strong_indices]\n",
    "v = convert_to_percentile(v)\n",
    "\n",
    "ResultPlotter.plot_mesh_with_points(\n",
    "    points=p[strong_indices],\n",
    "    opacity=0.2,\n",
    "    point_values=v,\n",
    "    points_on_surface=False,\n",
    "    marker_dict={\"size\": 1, \"colorscale\": \"Turbo\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacky way to do this but it's okay for now\n",
    "not_a_strike_names = np.asarray(\n",
    "    [\n",
    "        \"20240418_OB_1_rp\",\n",
    "        \"20240506_OB_7\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240502_OB_1\",\n",
    "        \"20240503_OB_4\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240418_OB_1\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240418_OB_1_rp\",\n",
    "        \"20240417_OB_1\",\n",
    "        \"20240418_OB_1_rp\",\n",
    "        \"20220427_OB_5\",\n",
    "        \"20240503_OB_3\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240418_OB_1_rp\",\n",
    "        \"20240418_OB_1_rp\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240503_OB_5\",\n",
    "        \"20240506_OB_7\",\n",
    "        \"20240417_OB_2\",\n",
    "        \"20240507_OB_2\",\n",
    "        \"20240417_OB_2\",\n",
    "        \"20240418_OB_1_rp\",\n",
    "        \"20240418_OB_1_rp\",\n",
    "        \"20240418_OB_1_rp\",\n",
    "        \"20240418_OB_1_rp\",\n",
    "        \"20240418_OB_1\",\n",
    "        \"20240506_OB_7\",\n",
    "        \"20240506_OB_7\",\n",
    "    ]\n",
    ")\n",
    "not_a_strike_numbers = np.asarray(\n",
    "    [\n",
    "        18,\n",
    "        14,\n",
    "        4,\n",
    "        10,\n",
    "        1,\n",
    "        9,\n",
    "        8,\n",
    "        16,\n",
    "        1,\n",
    "        10,\n",
    "        11,\n",
    "        16,\n",
    "        5,\n",
    "        15,\n",
    "        1,\n",
    "        5,\n",
    "        1,\n",
    "        5,\n",
    "        6,\n",
    "        15,\n",
    "        10,\n",
    "        4,\n",
    "        7,\n",
    "        4,\n",
    "        8,\n",
    "        12,\n",
    "        2,\n",
    "        5,\n",
    "        1,\n",
    "        14,\n",
    "        2,\n",
    "        6,\n",
    "        3,\n",
    "        1,\n",
    "        9,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def is_a_strike(specimen_name, strike_number):\n",
    "    indices = np.where(not_a_strike_names == specimen_name)\n",
    "    if len(indices) == 0:\n",
    "        return True\n",
    "    if strike_number in not_a_strike_numbers[indices[0]]:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_a_strike(\"20240418_OB_1\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results from the weakest strikes\n",
    "low_indices = np.argsort(scores)\n",
    "\n",
    "for i, idx in enumerate(low_indices):\n",
    "    if i <= 40 or i > 50:\n",
    "        continue\n",
    "\n",
    "    name = names[idx]\n",
    "    strike_number = strike_nums[idx]\n",
    "\n",
    "    indices = analyzer.get_specimen_indices(name, strike_number=strike_number)\n",
    "    points = analyzer.all_results[\"start_locations_mm\"][indices]\n",
    "    values = analyzer.all_results[\"displacement\"][indices][:, 2]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(points[:, 1], points[:, 0], c=values)\n",
    "    plt.title(\n",
    "        f\"\"\"{name}, strike {strike_number}\n",
    "              score: {scores[idx]} \n",
    "              strike? {is_a_strike(name, strike_number)} \n",
    "              mandible order {analyzer.all_results[\"mandible_order\"][indices][0]}\"\"\"\n",
    "    )\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some comparisons based on mandible order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram flow differences\n",
    "key = \"average_flow_error\"\n",
    "all_flow = torch.mean(torch.abs(analyzer.all_results[key]), axis=1)\n",
    "all_flow, _ = torch.sort(all_flow)\n",
    "\n",
    "# cut-off at some percentile\n",
    "cutoff = 0.995\n",
    "cutoff_index = int(len(all_flow) * cutoff)\n",
    "\n",
    "bins = plt.hist(all_flow[:cutoff_index], bins=50, alpha=0.5, label=\"all 3 cameras\")\n",
    "width = bins[1][1] - bins[1][0]\n",
    "\n",
    "# add in the top two\n",
    "flow = analyzer.get_top_values(key)\n",
    "flow, _ = torch.sort(torch.mean(torch.abs(flow), axis=1))\n",
    "flow = flow[:cutoff_index]\n",
    "bins = np.arange(min(flow), max(flow) + width, width)\n",
    "_ = plt.hist(flow, bins=bins, alpha=0.5, label=\"top 2 cameras\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Point Count\")\n",
    "plt.xlabel(\"Flow Error (pixels)\")\n",
    "plt.title(\"Flow error in region around strike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram flow differences\n",
    "key = \"average_flow_sq\"\n",
    "all_flow = torch.mean(torch.abs(analyzer.all_results[key]), axis=1)\n",
    "all_flow, _ = torch.sort(all_flow)\n",
    "\n",
    "# cut-off at some percentile\n",
    "cutoff = 0.95\n",
    "cutoff_index = int(len(all_flow) * cutoff)\n",
    "\n",
    "bins = plt.hist(all_flow[:cutoff_index], bins=50, alpha=0.5, label=\"all 3 cameras\")\n",
    "width = bins[1][1] - bins[1][0]\n",
    "\n",
    "# # add in the top two\n",
    "flow = analyzer.get_top_values(key)\n",
    "flow, _ = torch.sort(torch.mean(torch.abs(flow), axis=1))\n",
    "# cut-off at some percentile\n",
    "cutoff = 0.99\n",
    "cutoff_index = int(len(all_flow) * cutoff)\n",
    "flow = flow[:cutoff_index]\n",
    "bins = np.arange(min(flow), max(flow) + width, width)\n",
    "_ = plt.hist(flow, bins=bins, alpha=0.5, label=\"top 2 cameras\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Point Count\")\n",
    "plt.xlabel(\"Flow Error (pixels)\")\n",
    "plt.title(\"Flow error in region around strike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram flow differences\n",
    "key = \"average_huber_loss\"\n",
    "all_flow = torch.mean(torch.abs(analyzer.all_results[key]), axis=1)\n",
    "all_flow, _ = torch.sort(all_flow)\n",
    "\n",
    "# cut-off at some percentile\n",
    "cutoff = 0.995\n",
    "cutoff_index = int(len(all_flow) * cutoff)\n",
    "\n",
    "bins = plt.hist(all_flow[:cutoff_index], bins=50, alpha=0.5, label=\"all 3 cameras\")\n",
    "width = bins[1][1] - bins[1][0]\n",
    "\n",
    "# add in the top two\n",
    "flow = analyzer.get_top_values(key)\n",
    "flow, _ = torch.sort(torch.mean(torch.abs(flow), axis=1))\n",
    "flow = flow[:cutoff_index]\n",
    "bins = np.arange(min(flow), max(flow) + width, width)\n",
    "_ = plt.hist(flow, bins=bins, alpha=0.5, label=\"top 2 cameras\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Point Count\")\n",
    "plt.xlabel(\"Huber Loss\")\n",
    "plt.title(\"Huber Loss in region around strike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentile differences between huber and flow in top 2 cameras\n",
    "p0 = analyzer.get_percentile(\"average_flow_error\", num_cams=2)\n",
    "p1 = analyzer.get_percentile(\"average_flow_sq\", num_cams=2)\n",
    "\n",
    "diffs = torch.abs(p1 - p0)\n",
    "\n",
    "_ = plt.hist(diffs, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentile differences between huber and flow in top 2 cameras\n",
    "huber_percentiles = analyzer.get_percentile(\"average_huber_loss\", num_cams=2)\n",
    "flow_percentiles = analyzer.get_percentile(\"average_flow_error\", num_cams=2)\n",
    "\n",
    "diffs = torch.abs(huber_percentiles - flow_percentiles)\n",
    "\n",
    "_ = plt.hist(diffs, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at which points vary the most from their neighbors\n",
    "points = analyzer.all_results[\"start_locations_std\"]\n",
    "values = analyzer.all_results[\"normalized_displacement\"]\n",
    "tree = cKDTree(points)\n",
    "k = 25\n",
    "distances, indices = tree.query(points, k=k + 1)\n",
    "# exclude self\n",
    "neighbor_indices = indices[:, 1:]\n",
    "\n",
    "neighbor_avgs = values[neighbor_indices].mean(axis=1)\n",
    "difference = values - neighbor_avgs\n",
    "neighbor_diff_z = difference[:, 2]\n",
    "\n",
    "_ = plt.hist(torch.abs(neighbor_diff_z), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at which points vary the most from their neighbors, not normalized\n",
    "points = analyzer.all_results[\"start_locations_std\"]\n",
    "values = analyzer.all_results[\"displacement\"]\n",
    "tree = cKDTree(points)\n",
    "k = 25\n",
    "distances, indices = tree.query(points, k=k + 1)\n",
    "# exclude self\n",
    "neighbor_indices = indices[:, 1:]\n",
    "\n",
    "neighbor_avgs = values[neighbor_indices].mean(axis=1)\n",
    "difference = values - neighbor_avgs\n",
    "neighbor_diff_z = difference[:, 2]\n",
    "\n",
    "_ = plt.hist(torch.abs(neighbor_diff_z), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at some points with bad flow\n",
    "array = torch.mean(analyzer.get_top_values(\"average_flow_sq\", num_cams=2), axis=1)\n",
    "array = neighbor_diff_z\n",
    "\n",
    "\n",
    "index = get_random_percentile_index(array.numpy(), 95, 100)\n",
    "\n",
    "specimen_number = analyzer.all_results[\"specimen_number\"][index]\n",
    "point_number = int(analyzer.all_results[\"point_number\"][index])\n",
    "strike_number = int(analyzer.all_results[\"strike_number\"][index])\n",
    "\n",
    "print(specimen_number, \"point\", point_number, \"strike\", strike_number)\n",
    "print(\"flow error: {:.5f} pixels\".format(array[index]))\n",
    "print(\n",
    "    \"percentile: {:.0f}%\".format(\n",
    "        100 * get_percentiles(array.numpy(), float(array[index]))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specimen_number = \"20240503_OB_3\"\n",
    "# point_number = 15\n",
    "# strike_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specimen_number = str(analyzer.all_results[\"specimen_number\"][0])\n",
    "# point_number = 30\n",
    "# strike_number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices related to this strike\n",
    "indices1 = np.where(analyzer.all_results[\"specimen_number\"] == specimen_number)[0]\n",
    "indices2 = np.where(analyzer.all_results[\"strike_number\"] == strike_number)[0]\n",
    "\n",
    "indices = np.intersect1d(indices1, indices2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"test_full_results_from_manual_strike_transfer/{specimen_number}/strike_{strike_number}_results.json\"\n",
    "assert os.path.exists(filename)\n",
    "\n",
    "result_info = load_dictionary(filename)\n",
    "\n",
    "\n",
    "plotter = ResultPlotter(result_info)\n",
    "\n",
    "\n",
    "# result_info[\"point_numbers\"]\n",
    "\n",
    "\n",
    "# plotter.result_info[\"removed_points\"]\n",
    "\n",
    "\n",
    "# plotter.result_info[\"points_used_in_gm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = torch.mean(analyzer.get_top_values(\"average_flow_sq\", num_cams=2), axis=1)\n",
    "error_values = array[indices]\n",
    "good_point_indices = error_values < 0.0015\n",
    "fig = plotter.scatter_values(error_values, highlight_point=point_number)\n",
    "\n",
    "# mark the points above the error threshold with a red x\n",
    "ant_start_locs = plotter.result_manager.point_start_locs_ant_mm\n",
    "ant_start_locs = ant_start_locs[np.where(~good_point_indices)]\n",
    "ax = fig.axes[0]\n",
    "ax.scatter(ant_start_locs[:, 1], ant_start_locs[:, 0], marker=\"x\", color=\"red\", s=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_diffs = plotter.result_manager.flow_diff_around_strike()\n",
    "_, sorted = sort_by_camera(flow_diffs[:, :, None], treat_individually=False)\n",
    "values = sorted.squeeze()[:, :2]\n",
    "values = torch.mean(values, axis=1)\n",
    "_ = plotter.scatter_values(values, highlight_point=point_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.scatter_peak_disp(highlight_point=point_number, cmap=\"turbo\")\n",
    "\n",
    "# mark the points above the error threshold with a black x\n",
    "ant_start_locs = plotter.result_manager.point_start_locs_ant_mm\n",
    "ant_start_locs = ant_start_locs[np.where(~good_point_indices)]\n",
    "ax = plt.gca()\n",
    "ax.scatter(ant_start_locs[:, 1], ant_start_locs[:, 0], marker=\"x\", color=\"black\", s=15)\n",
    "\n",
    "plotter.scatter_peak_disp(highlight_point=point_number, cmap=\"turbo\", with_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plotter.plot_camera_weight(point_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plotter.plot_displacement(point_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.show_flow_differences(point_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotter.plot_all_displacement(highlight_point=point_number)\n",
    "\n",
    "# highlight the points below the error threshold in blue\n",
    "ax = fig.axes[0]\n",
    "bad_disp = plotter.result_manager.rel_displacements[~good_point_indices]\n",
    "for p in bad_disp:\n",
    "    plt.plot(p[:, 2] * 1e3, \"--\", color=(0.5, 0.5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = plotter.make_point_track_video(highlight_point=point_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = plotter.get_arrow_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = plotter.result_manager.point_mesh_locations\n",
    "ResultPlotter.plot_mesh_with_points(points=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into more:\n",
    "# 20240507_OB_2 point 31 strike 10\n",
    "# 20240502_OB_6 29\n",
    "# 20240502_OB_2 alignment is super off\n",
    "# \"20220422_OB_1\" something is wrong with strikes 6 and 7\n",
    "\n",
    "# good examples\n",
    "# 20240418_OB_1 barely any movement but clear pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggested threshold for being used in global movement calculation:\n",
    "# 0.025 average error with top two cameras\n",
    "# in region surrounding peak\n",
    "# or... maybe squared error of 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at results on the mesh\n",
    "# with ONLY points below the error threshold\n",
    "array = torch.mean(analyzer.get_top_values(\"average_flow_sq\", num_cams=2), axis=1)\n",
    "good_indices = array < 0.0015\n",
    "# good_indices = ~good_indices\n",
    "p = analyzer.all_results[\"mesh_points\"][good_indices]\n",
    "\n",
    "# jitter the points\n",
    "\n",
    "jitter = 1000\n",
    "rand = (torch.rand(p.shape) - 0.5) * jitter\n",
    "p = p + rand\n",
    "v = analyzer.all_results[\"normalized_displacement\"][good_indices, 2]\n",
    "v = convert_to_percentile(v)\n",
    "\n",
    "ResultPlotter.plot_mesh_with_points(\n",
    "    points=p,\n",
    "    opacity=0.1,\n",
    "    point_values=v,\n",
    "    points_on_surface=False,\n",
    "    marker_dict={\"size\": 2, \"colorscale\": \"bluered\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scattering the same stuff\n",
    "array = torch.mean(analyzer.get_top_values(\"average_flow_sq\", num_cams=2), axis=1)\n",
    "good_indices = array < 0.0015\n",
    "\n",
    "p = analyzer.all_results[\"start_locations_std\"]\n",
    "jitter = 30\n",
    "rand = (torch.rand(p.shape) - 0.5) * jitter\n",
    "p = p + rand\n",
    "\n",
    "v = analyzer.all_results[\"normalized_displacement\"][:, 2]\n",
    "v = convert_to_percentile(v)\n",
    "plt.scatter(\n",
    "    p[good_indices, 1],\n",
    "    p[good_indices, 0],\n",
    "    s=1.5,\n",
    "    c=v[good_indices],\n",
    "    cmap=\"coolwarm\",\n",
    "    clim=(0, 100),\n",
    ")\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(\n",
    "    p[~good_indices, 1],\n",
    "    p[~good_indices, 0],\n",
    "    s=1.5,\n",
    "    c=v[~good_indices],\n",
    "    cmap=\"coolwarm\",\n",
    "    clim=(0, 100),\n",
    ")\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some strikes that don't look good\n",
    "# based on differences from nearby points\n",
    "# 20220427_OB_3 strike 2 (this whole ant might be weird, look closer)\n",
    "# we know 20240503_OB_3 was having issues\n",
    "# check on what other samples had to change the error threshold\n",
    "# for global movement calculation\n",
    "\n",
    "# 20220427_OB_4 is interesting because most of the seleted points\n",
    "# are in the saddle - probably makes computing normalized movement weird\n",
    "# might want to think about other ways to get like a normalized score...\n",
    "# like thinking about how much on average the points in that strike deviate\n",
    "# from the expected strike strength in that region\n",
    "\n",
    "# 20240507_OB_3 strike 9, example of a super weak strike that doesn't follow\n",
    "# expected patterns. a lot of strikes from this ant look weak... investigate more\n",
    "\n",
    "# you need to check on how many points made it over in later strikes\n",
    "# for instance 20240502_OB_3 strike 9 has very few points\n",
    "# it could be worth not actually dropping points that aren't CRAZY off\n",
    "# but just saving information about the liklihood that the track was good\n",
    "# and maybe just acknowledging in that way that it COULD be a different point\n",
    "\n",
    "# 20240506_OB_7 strike 2, take a look at alignment here. Points are all really low\n",
    "\n",
    "# 20240503_OB_3 strike 1 in particular, something is really weird here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024/11/13\n",
    "# goal for today:\n",
    "# define some initial metric for a strength score\n",
    "# then you can use that to do normalized strength measurements\n",
    "# and also threshold strikes based on the strength score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through and look at images from every strike\n",
    "i = 30\n",
    "specimen_numbers = MetadataManager.all_specimen_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_displacement(\n",
    "        self, dim=2, relative=True, highlight_point=None, good_only=True,\n",
    "        metadata_manager=None, crop=False, error_scores=None\n",
    "    ):\n",
    "        if relative:\n",
    "            disp = torch.asarray(self.result_info[\"rel_displacements\"])\n",
    "        else:\n",
    "            disp = torch.asarray(self.result_info[\"camera_point_displacements\"])\n",
    "        disp = disp[:, :, dim] * 1e3\n",
    "\n",
    "        if good_only and self.good_indices is not None:\n",
    "            disp_ = disp[self.good_indices]\n",
    "        else:\n",
    "            disp_ = disp\n",
    "\n",
    "        fig = plt.figure()\n",
    "        for i, p in enumerate(disp_):\n",
    "            # hardcoding for now... \n",
    "            if error_scores is not None: \n",
    "                assert len(error_scores) == len(disp_)\n",
    "                score = error_scores[i]\n",
    "                cmap = matplotlib.cm.turbo \n",
    "                color = cmap(score / 0.0015)\n",
    "            else:\n",
    "                color = 'black'\n",
    "            plt.plot(p, color=color)\n",
    "        if highlight_point is not None:\n",
    "            point_index = torch.where(\n",
    "                torch.asarray(self.result_info[\"point_numbers\"]) == highlight_point\n",
    "            )[0][0]\n",
    "            plt.plot(disp[point_index], color=\"red\", label=f\"point {highlight_point}\")\n",
    "\n",
    "        plt.xlabel(\"Frame #\")\n",
    "        plt.ylabel(\"Displacement (um)\")\n",
    "\n",
    "        if metadata_manager is not None:\n",
    "            start_frames = metadata_manager.mandible_start_frames(strike_number=strike_num)\n",
    "            if start_frames[0] == start_frames[1]:\n",
    "                plt.axvline(x=start_frames[0], label=\"both mandibles\", color='purple')\n",
    "            else:\n",
    "                plt.axvline(x=start_frames[0], label=\"left mandible\", color='blue')\n",
    "                plt.axvline(x=start_frames[1], label=\"right mandible\", color='red')\n",
    "            plt.legend()\n",
    "\n",
    "        if crop:\n",
    "            strike_center_index = self.result_manager.strike_center_index() \n",
    "            ax = plt.gca()\n",
    "            ax.set_xlim(strike_center_index - 5, strike_center_index + 5)\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = specimen_numbers[i]\n",
    "strike_numbers = MetadataManager(num).strike_numbers\n",
    "error_threshold = 0.0015\n",
    "mm = MetadataManager(num)\n",
    "for strike_num in strike_numbers:\n",
    "    filename = get_filename(num, strike_num)\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"no file for {num}, strike {strike_num}\")\n",
    "        continue\n",
    "\n",
    "    info = load_dictionary(filename)\n",
    "    result_manager = ResultManager(info)\n",
    "    error_scores = result_manager.error_scores\n",
    "    good_indices = torch.where(error_scores < error_threshold)\n",
    "    plotter = ResultPlotter(\n",
    "        info, good_indices=torch.where(error_scores < error_threshold)\n",
    "    )\n",
    "    fig = plotter.scatter_peak_disp(with_image=True)\n",
    "    ax = plt.gca() \n",
    "    ax.set_title(f\"{num}, {strike_num}\")\n",
    "    bad_indices = torch.where(error_scores >= error_threshold)\n",
    "    #for bi in bad_indices:\n",
    "    locations = result_manager.point_start_locs_ant_mm[bad_indices]\n",
    "    ax.scatter(locations[:, 1], locations[:, 0], color='gray')\n",
    "\n",
    "    plot_all_displacement(plotter, metadata_manager=mm,\n",
    "                          error_scores=error_scores[good_indices])\n",
    "    plot_all_displacement(plotter, metadata_manager=mm, crop=True,\n",
    "                          error_scores=error_scores[good_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = plotter.get_arrow_video(good_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(video[6:45], fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in specimen_numbers:\n",
    "    mm = MetadataManager(num)\n",
    "    strike_numbers = mm.strike_numbers\n",
    "    \n",
    "    for sn in strike_numbers:\n",
    "        filename = mm.video_filename(strike_number=sn)\n",
    "        #if str(sn) not in filename[-10:]:\n",
    "        print(num, sn, Path(filename).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsflfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
