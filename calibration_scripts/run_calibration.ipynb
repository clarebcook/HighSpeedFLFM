{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from hsflfm.config import home_directory\n",
    "from hsflfm.util import (\n",
    "    load_graph_images,\n",
    "    load_dictionary,\n",
    "    generate_A_matrix,\n",
    "    MetadataManager,\n",
    ")\n",
    "from hsflfm.calibration import (\n",
    "    CalibrationInfoManager,\n",
    "    SystemVertexParser,\n",
    "    SystemCalibrator,\n",
    "    FLF_System,\n",
    ")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Parse Vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration filename can be manually specified or pulled from stored metadata\n",
    "# the specified specimen can be any specimen that was filmed on the under these calibration conditions\n",
    "specimen = \"20240506_OB_6\"\n",
    "\n",
    "mm = MetadataManager(specimen)\n",
    "\n",
    "calibration_filename = mm.calibration_filename\n",
    "\n",
    "calibration_folder = mm.calibration_folder\n",
    "\n",
    "\n",
    "info_manager = CalibrationInfoManager(calibration_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known information\n",
    "info_manager.vertex_spacing_m = 500e-6  # spacing between vertices on the graph target\n",
    "info_manager.pixel_size = 52e-6  # pixel size in meters of the camera\n",
    "\n",
    "info_manager.save_all_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the manager enough information to find the graph images\n",
    "# this may need to be changed if different naming conventions were used\n",
    "# the dictionary just needs to contain a substring that is unique to the specific plane image\n",
    "\n",
    "plane_names = np.sort([i for i in os.listdir(calibration_folder) if \"tiff\" in i])\n",
    "name_dict = {}\n",
    "for i, name in enumerate(plane_names):\n",
    "    name_dict[i] = name\n",
    "info_manager.plane_names = name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one image to identify where images should be cropped\n",
    "# Right now, crops are expected to be the same size for all views\n",
    "\n",
    "# standard crops for 3 camera system\n",
    "crop_indices = {\n",
    "    0: [230, 480, 0, 200],\n",
    "    1: [230, 480, 440, 640],\n",
    "    2: [0, 250, 220, 420],\n",
    "}\n",
    "\n",
    "# standard crops for 6 camera system\n",
    "# crop_indices = {\n",
    "#     0: [20, 250, 0, 210],\n",
    "#     1: [250, 480, 0, 210],\n",
    "#     2: [20, 250, 220, 430],\n",
    "#     3: [250, 480, 220, 430],\n",
    "#     4: [20, 250, 430, 640],\n",
    "#     5: [250, 480, 430, 640]\n",
    "# }\n",
    "\n",
    "# crop_indices = {\n",
    "#     0: [10, 240,10, 220],\n",
    "#     1: [240, 470, 0, 210],\n",
    "#     2: [10, 240, 240, 450],\n",
    "#     3: [240, 470, 220, 430],\n",
    "#     4: [10, 240, 460, 640],\n",
    "#     5: [240, 470, 430, 640]\n",
    "# }\n",
    "\n",
    "# this could be done with any image, including of an ant\n",
    "image_filename = calibration_folder + \"/\" + plane_names[0]\n",
    "raw_image = Image.open(image_filename)\n",
    "plt.imshow(raw_image)\n",
    "ax = plt.gca()\n",
    "for c in crop_indices.values():\n",
    "    rect = Rectangle((c[2], c[0]), c[3] - c[2], c[1] - c[0], fill=False, color=\"red\")\n",
    "    ax.add_artist(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_manager.crop_indices = crop_indices\n",
    "info_manager.save_all_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the images\n",
    "all_images = load_graph_images(\n",
    "    folder=calibration_folder, calibration_filename=calibration_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view one image to get the expected spacing between lines\n",
    "plt.figure()\n",
    "plt.imshow(all_images[0][0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_spacing = 160 - 135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = SystemVertexParser(\n",
    "    calibration_filename,\n",
    "    expected_vertex_spacing=expected_spacing,\n",
    "    all_images=all_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to adjust settings for finding the lines in the images\n",
    "# Settings used here for a test image will automatically be used for remaining images\n",
    "# if this is used to adjust settings for multiple images, it becomes slightly complicated\n",
    "# which settings are used for which images. This eventually needs to be fixed or documented better.\n",
    "\n",
    "\n",
    "threshold_values = {\n",
    "\n",
    "    # used in \"cv2.adaptiveThreshold\" to convert graph images to binary images\n",
    "\n",
    "    # should be an odd number that approximately matches the expected spacing\n",
    "\n",
    "    \"adaptive_threshold_range\": 23,\n",
    "\n",
    "    # used in cv2.medianBlur to filter the binary image\n",
    "\n",
    "    # larger numbers will blur out smaller features in the image other than the\n",
    "\n",
    "    # graph lines we are trying to identify\n",
    "\n",
    "    \"blur_range\": 3,\n",
    "\n",
    "    # \"edge_thresh\" and \"edge_aperture\" are used in cv2.Canny\n",
    "\n",
    "    # to identify edges in the images.\n",
    "\n",
    "    # consult cv2 documentation for use\n",
    "\n",
    "    \"edge_thresh1\": 100,\n",
    "\n",
    "    \"edge_thresh2\": 140,\n",
    "\n",
    "    \"edge_aperture\": 5,\n",
    "\n",
    "    # line_thresh_per_pixel * #pixel used in cv2.HoughLines to\n",
    "\n",
    "    # identify lines from edges\n",
    "\n",
    "    \"line_thresh_per_pixel\": 0.55,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "camera_number = 0\n",
    "\n",
    "plane_number = 0\n",
    "\n",
    "parser.find_lines(\n",
    "    camera_number,\n",
    "    plane_number,\n",
    "    show=True,\n",
    "    threshold_values=threshold_values,\n",
    "    show_process=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.find_all_remaining_lines(show=False, max_display=1000)\n",
    "parser.save_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for \"ValueError: cannot convert float NaN to integer\"\n",
    "# just pick a different camera number or plane number to look at\n",
    "parser.find_vertices(camera_number=0, plane_number=0, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be uncommented to help figure out why a point was not found\n",
    "# near a given location\n",
    "\n",
    "# parser.debug_missing_point(4, 0, (80, 170))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.find_all_remaining_vertices(show=False, max_display=200)\n",
    "parser.remove_nan_points()\n",
    "parser.save_all_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Remove extraneous vertices\n",
    "\n",
    "While this step can be improved in future versions, right now extraneous vertices must be manually removed, or they will impact the calibration results. This can be done by running ``remove_vertices.py`` (first open the file and adjust necessary settings, particularly the file names). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: identify approximate alignment points between images\n",
    "\n",
    "This step can likely be automated in future versions of the code, but right now the user must manually select approximate alignment points between the images. This can be done by finding a feature visible in all images, then running ``select_alignment_points.py`` to click on that point in all the images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Fit calibration coefficients\n",
    "\n",
    "In this portion, the identified graph vertices are used to perform inter- and intr-camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be uncommented to display interactive plots\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_camera = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select reference plane based on how many vertices were identified in each plane\n",
    "# the first number gives the total number of vertices identified in a given plane\n",
    "# between all images\n",
    "# and the second number is the number of identified vertices in the image with the\n",
    "# least identified vertices.\n",
    "# both of these numbers should be reasonably large in the chosen reference plane\n",
    "vertices = load_dictionary(calibration_filename)[\"all_vertices\"]\n",
    "\n",
    "for plane_num, values in vertices.items():\n",
    "    plane_points = 0\n",
    "    min_points = np.inf\n",
    "    for cam, points in values.items():\n",
    "        plane_points = plane_points + len(points)\n",
    "        min_points = min(min_points, len(points))\n",
    "    print(\n",
    "        plane_num,\n",
    "        \"total points:\",\n",
    "        plane_points,\n",
    "        \", mininum points in an image:\",\n",
    "        min_points,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_plane = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_separation_mm = 0.381  # this is the step size most often used between planes\n",
    "calibrator = SystemCalibrator(\n",
    "    calibration_filename=calibration_filename,\n",
    "    reference_plane=reference_plane,\n",
    "    reference_camera=reference_camera,\n",
    "    plane_separation_mm=plane_separation_mm,\n",
    "    ref_plane_image_folder=None,\n",
    "    useable_plane_numbers=None,  # if None, this will use all planes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator.run_inter_camera_calibration(show=True, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator.run_slope_calibration(show=True, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: check if results look reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = FLF_System(calibration_filename)\n",
    "all_camera_vertices_matrices = calibrator.all_camera_vertices_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_comparison_plot(camera_number, vector_length_mm=None):\n",
    "    slope0, slope1 = calibrator.get_slopes_from_vertices_matrices(camera_number)\n",
    "    vertices_matrices = all_camera_vertices_matrices[camera_number]\n",
    "\n",
    "    plt.figure()\n",
    "    matrix_shape = vertices_matrices.shape[1:3]\n",
    "    first = True\n",
    "    for i, j in np.ndindex(matrix_shape):\n",
    "        if first:\n",
    "            label1 = \"Comptuted slope vector\"\n",
    "            label2 = \"Fit slope\"\n",
    "            label3 = \"Vertex locations\"\n",
    "        else:\n",
    "            label1 = None\n",
    "            label2 = None\n",
    "            label3 = None\n",
    "\n",
    "        X = vertices_matrices[:, i, j, 0]\n",
    "        Y = vertices_matrices[:, i, j, 1]\n",
    "\n",
    "        if not np.isnan(slope0[i, j]):\n",
    "            if vector_length_mm is None:\n",
    "                start_plane_mm = (\n",
    "                    np.where(~np.isnan(X))[0][0] - system.reference_plane\n",
    "                ) * plane_separation_mm\n",
    "                end_plane_mm = (\n",
    "                    np.where(~np.isnan(X))[0][-1] - system.reference_plane\n",
    "                ) * plane_separation_mm\n",
    "            else:\n",
    "                start_plane_mm = -vector_length_mm / 2\n",
    "                end_plane_mm = vector_length_mm / 2\n",
    "\n",
    "            x = vertices_matrices[system.reference_plane, i, j, 0]\n",
    "            y = vertices_matrices[system.reference_plane, i, j, 1]\n",
    "\n",
    "            # plot the slope vector that was fit to that point\n",
    "            coeff0, coeff1 = system._get_slope_coeffs(camera_number)\n",
    "            slope_matrix = generate_A_matrix(system.slope_order, [x], [y])\n",
    "            v1 = np.matmul(slope_matrix, coeff0)[0]\n",
    "            v0 = np.matmul(slope_matrix, coeff1)[0]\n",
    "            x_start = x + v0 * start_plane_mm\n",
    "            x_end = x + v0 * end_plane_mm\n",
    "            y_start = y + v1 * start_plane_mm\n",
    "            y_end = y + v1 * end_plane_mm\n",
    "            plt.plot(\n",
    "                [x_start, x, x_end],\n",
    "                [y_start, y, y_end],\n",
    "                \"-\",\n",
    "                linewidth=3,\n",
    "                color=\"blue\",\n",
    "                label=label2,\n",
    "            )\n",
    "\n",
    "            s0 = slope0[i, j]\n",
    "            s1 = slope1[i, j]\n",
    "            x_start = x + s0 * start_plane_mm / plane_separation_mm\n",
    "            x_end = x + s0 * end_plane_mm / plane_separation_mm\n",
    "            y_start = y + s1 * start_plane_mm / plane_separation_mm\n",
    "            y_end = y + s1 * end_plane_mm / plane_separation_mm\n",
    "\n",
    "            # plot the originally calculated slope vector\n",
    "            plt.plot(\n",
    "                [x_start, x, x_end],\n",
    "                [y_start, y, y_end],\n",
    "                \"-\",\n",
    "                markersize=2,\n",
    "                color=\"orange\",\n",
    "                label=label1,\n",
    "            )\n",
    "\n",
    "        if False in np.isnan(X):\n",
    "            plt.plot(X, Y, \".\", markersize=3, color=\"red\", label=label3)\n",
    "            first = False\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    if vector_length_mm is not None:\n",
    "        title = f\"Slopes for camera {camera_number}, \\n shown for {vector_length_mm} mm axial shift\"\n",
    "    else:\n",
    "        title = f\"Slopes for camera {camera_number}, \\n vector length varies to match location of located vertices\"\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.xlim([0, 200])\n",
    "    plt.ylim([0, 250])\n",
    "    plt.tight_layout()\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "\n",
    "for cam in system.calib_manager.image_numbers:\n",
    "    make_comparison_plot(cam, vector_length_mm=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (480, 640)\n",
    "\n",
    "maxv = -np.inf\n",
    "minv = np.inf\n",
    "\n",
    "calib_manager = system.calib_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(0, image_shape[1])\n",
    "ax.set_ylim(0, image_shape[0])\n",
    "\n",
    "cmap = matplotlib.cm.turbo\n",
    "\n",
    "minv = 0\n",
    "\n",
    "for cam_num, indices in calib_manager.crop_indices.items():\n",
    "    corner = (indices[2], indices[0])\n",
    "    width = indices[3] - indices[2]\n",
    "    height = indices[1] - indices[0]\n",
    "\n",
    "    rect = Rectangle(corner, width, height, fill=None, linewidth=2)\n",
    "    ax.add_artist(rect)\n",
    "\n",
    "    spacing = 25\n",
    "    x_locs = np.linspace(\n",
    "        spacing, height - spacing, int((height - 2 * spacing) / spacing)\n",
    "    )\n",
    "    y_locs = np.linspace(spacing, width - spacing, int((width - 2 * spacing) / spacing))\n",
    "\n",
    "    # for i, j in np.ndindex((len(x_locs), len(y_locs))):\n",
    "    #    x = x_locs[i]\n",
    "    #    y = y_locs[j]\n",
    "    y_coords, x_coords = np.meshgrid(y_locs, x_locs)\n",
    "    y_coords = y_coords.flatten()\n",
    "    x_coords = x_coords.flatten()\n",
    "    all_v0, all_v1 = system.get_pixel_shifts(cam_num, x_coords, y_coords)\n",
    "\n",
    "    for x, y, v0, v1 in zip(x_coords, y_coords, all_v0, all_v1):\n",
    "        startx = x - v0 / 2 + indices[0]\n",
    "        starty = y - v1 / 2 + indices[2]\n",
    "\n",
    "        norm = np.sqrt(v0**2 + v1**2)\n",
    "        norm = (norm - minv) / (maxv - minv)\n",
    "        color = cmap(norm)\n",
    "        if cam_num != calib_manager.reference_camera:\n",
    "            plt.arrow(starty, startx, v1, v0, head_width=5, color=color)\n",
    "\n",
    "    norms = np.sqrt(all_v0**2 + all_v1**2)\n",
    "    maxv = max(np.max(norms), maxv)\n",
    "    # minv = min(np.min(norms), minv)\n",
    "\n",
    "    if cam_num == calib_manager.reference_camera:\n",
    "        x_coords = x_coords + indices[0]\n",
    "        y_coords = y_coords + indices[2]\n",
    "        plt.scatter(y_coords, x_coords, color=cmap(0), s=2)\n",
    "    # break\n",
    "\n",
    "\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(0, image_shape[1])\n",
    "ax.set_ylim(0, image_shape[0])\n",
    "\n",
    "cmap = matplotlib.cm.turbo\n",
    "\n",
    "minv = 0\n",
    "\n",
    "for cam_num, indices in calib_manager.crop_indices.items():\n",
    "    corner = (indices[2], indices[0])\n",
    "    width = indices[3] - indices[2]\n",
    "    height = indices[1] - indices[0]\n",
    "\n",
    "    rect = Rectangle(corner, width, height, fill=None, linewidth=2)\n",
    "    ax.add_artist(rect)\n",
    "\n",
    "    spacing = 25\n",
    "    x_locs = np.linspace(\n",
    "        spacing, height - spacing, int((height - 2 * spacing) / spacing)\n",
    "    )\n",
    "    y_locs = np.linspace(spacing, width - spacing, int((width - 2 * spacing) / spacing))\n",
    "\n",
    "    # for i, j in np.ndindex((len(x_locs), len(y_locs))):\n",
    "    #    x = x_locs[i]\n",
    "    #    y = y_locs[j]\n",
    "    y_coords, x_coords = np.meshgrid(y_locs, x_locs)\n",
    "    y_coords = y_coords.flatten()\n",
    "    x_coords = x_coords.flatten()\n",
    "    all_v0, all_v1 = system.get_shift_slopes(cam_num, x_coords, y_coords)\n",
    "\n",
    "    for x, y, v0, v1 in zip(x_coords, y_coords, all_v0, all_v1):\n",
    "        startx = x - v0 / 2 + indices[0]\n",
    "        starty = y - v1 / 2 + indices[2]\n",
    "\n",
    "        norm = np.sqrt(v0**2 + v1**2)\n",
    "        norm = (norm - minv) / (maxv - minv)\n",
    "        color = cmap(norm)\n",
    "        # if cam_num != calib_manager.reference_camera:\n",
    "        plt.arrow(starty, startx, v1, v0, head_width=5, color=color)\n",
    "\n",
    "    norms = np.sqrt(all_v0**2 + all_v1**2)\n",
    "    maxv = max(np.max(norms), maxv)\n",
    "\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsflfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
